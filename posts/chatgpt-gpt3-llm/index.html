<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>ChatGPT, LLMs and Black Boxes | Alex Su ⌗ personal</title>
<meta name="keywords" content="">
<meta name="description" content="Large language models (LLMs) like GPT-3 can be incredibly helpful tools for generating text quickly and accurately. However, it&rsquo;s important to remember that LLMs are not sentient beings and they don&rsquo;t truly understand the meaning behind the language they generate. Instead, they use mathematical models to predict the most likely response based on their training data. To use LLMs effectively, it&rsquo;s important to be mindful of the data that&rsquo;s being used to train them.">
<meta name="author" content="Alex Su">
<link rel="canonical" href="https://alex-y-su.github.io/posts/chatgpt-gpt3-llm/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://alex-y-su.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://alex-y-su.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://alex-y-su.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://alex-y-su.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://alex-y-su.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://alex-y-su.github.io/posts/chatgpt-gpt3-llm/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-79258419-2', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="ChatGPT, LLMs and Black Boxes" />
<meta property="og:description" content="Large language models (LLMs) like GPT-3 can be incredibly helpful tools for generating text quickly and accurately. However, it&rsquo;s important to remember that LLMs are not sentient beings and they don&rsquo;t truly understand the meaning behind the language they generate. Instead, they use mathematical models to predict the most likely response based on their training data. To use LLMs effectively, it&rsquo;s important to be mindful of the data that&rsquo;s being used to train them." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://alex-y-su.github.io/posts/chatgpt-gpt3-llm/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-23T17:46:20+08:00" />
<meta property="article:modified_time" content="2023-02-23T17:46:20+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="ChatGPT, LLMs and Black Boxes"/>
<meta name="twitter:description" content="Large language models (LLMs) like GPT-3 can be incredibly helpful tools for generating text quickly and accurately. However, it&rsquo;s important to remember that LLMs are not sentient beings and they don&rsquo;t truly understand the meaning behind the language they generate. Instead, they use mathematical models to predict the most likely response based on their training data. To use LLMs effectively, it&rsquo;s important to be mindful of the data that&rsquo;s being used to train them."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://alex-y-su.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "ChatGPT, LLMs and Black Boxes",
      "item": "https://alex-y-su.github.io/posts/chatgpt-gpt3-llm/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ChatGPT, LLMs and Black Boxes",
  "name": "ChatGPT, LLMs and Black Boxes",
  "description": "Large language models (LLMs) like GPT-3 can be incredibly helpful tools for generating text quickly and accurately. However, it\u0026rsquo;s important to remember that LLMs are not sentient beings and they don\u0026rsquo;t truly understand the meaning behind the language they generate. Instead, they use mathematical models to predict the most likely response based on their training data. To use LLMs effectively, it\u0026rsquo;s important to be mindful of the data that\u0026rsquo;s being used to train them.",
  "keywords": [
    
  ],
  "articleBody": "Large language models (LLMs) like GPT-3 can be incredibly helpful tools for generating text quickly and accurately. However, it’s important to remember that LLMs are not sentient beings and they don’t truly understand the meaning behind the language they generate. Instead, they use mathematical models to predict the most likely response based on their training data. To use LLMs effectively, it’s important to be mindful of the data that’s being used to train them. Biases in the data can impact the output of an LLM. Additionally, it’s important to think of LLMs as tools that can help accomplish specific goals, rather than as black boxes that we can’t control.\nGPT-3 is a general-purpose language model that can generate text in response to a given prompt, while ChatGPT is a language model specifically designed and trained to generate more natural and engaging conversations with users in the context of chatbots or virtual assistants.\nGPT-3 A large language model developed by OpenAI Trained on a massive amount of text data Designed to generate text in response to a given prompt Can be used for text completion, translation, summarization, and creative writing Can generate text in a conversational style if prompted appropriately ChatGPT A version of GPT-3 that has been fine-tuned on a large dataset of conversational data Designed to be used in chatbots or virtual assistants to provide more human-like interactions with users Specifically trained to generate more natural and engaging conversations with users Goal is to simulate human conversation as closely as possible Can generate text in response to natural language inputs from users ChatGPT uses a technique called “contextualization” to incorporate the previous turns of the conversation into its responses. When a user inputs a message, ChatGPT analyzes the message along with the previous messages in the conversation to generate a response that is relevant to the ongoing discussion.\nBy using contextualization, ChatGPT is able to maintain coherence and relevancy throughout a conversation. But while contextualization is an important technique that allows ChatGPT to incorporate previous turns in a conversation into its responses, it can also potentially affect the correctness of its replies.\nOne potential issue with contextualization is that if the previous messages in the conversation are unclear, ambiguous, or incorrect, ChatGPT may use this flawed context to generate its response, resulting in an incorrect or irrelevant reply. Additionally, if a conversation takes unexpected turns or introduces new concepts or topics that are outside the scope of the data that ChatGPT was trained on, it may generate less accurate or less relevant responses.\nAccess to full GPT3.5 model: https://platform.openai.com/playground/ (at the time of publishing)\nWritten with my co-writer, ChatGPT.\n",
  "wordCount" : "440",
  "inLanguage": "en",
  "datePublished": "2023-02-23T17:46:20+08:00",
  "dateModified": "2023-02-23T17:46:20+08:00",
  "author":{
    "@type": "Person",
    "name": "Alex Su"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://alex-y-su.github.io/posts/chatgpt-gpt3-llm/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Alex Su ⌗ personal",
    "logo": {
      "@type": "ImageObject",
      "url": "https://alex-y-su.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://alex-y-su.github.io/" accesskey="h" title="Alex Su ⌗ personal (Alt + H)">Alex Su ⌗ personal</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://alex-y-su.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      ChatGPT, LLMs and Black Boxes
    </h1>
    <div class="post-meta"><span title='2023-02-23 17:46:20 +0800 +0800'>February 23, 2023</span>&nbsp;·&nbsp;Alex Su

</div>
  </header> 
  <div class="post-content"><p>Large language models (LLMs) like GPT-3 can be incredibly helpful tools for generating text quickly and accurately.
However, it&rsquo;s important to remember that LLMs are not sentient beings and they don&rsquo;t truly understand the meaning behind
the language they generate. Instead, they use mathematical models to <strong>predict</strong> the <strong>most likely</strong> response based on
their training data. To use LLMs effectively, it&rsquo;s important to be mindful of the data that&rsquo;s being used to train them.
Biases in the data can impact the output of an LLM. Additionally, it&rsquo;s important to think of LLMs as tools that can help
accomplish specific goals, rather than as black boxes that we can&rsquo;t control.</p>
<p>GPT-3 is a general-purpose language model that can generate text in response to a given prompt, while ChatGPT is a
language model <strong>specifically</strong> designed and <strong>trained</strong> to generate more natural and engaging conversations with users
in the context of chatbots or virtual assistants.</p>
<h4 id="gpt-3">GPT-3<a hidden class="anchor" aria-hidden="true" href="#gpt-3">#</a></h4>
<ul>
<li>A large language model developed by OpenAI</li>
<li>Trained on a massive amount of text data</li>
<li>Designed to generate text in response to a given prompt</li>
<li>Can be used for text completion, translation, summarization, and creative writing</li>
<li>Can generate text in a conversational style if prompted appropriately</li>
</ul>
<h4 id="chatgpt">ChatGPT<a hidden class="anchor" aria-hidden="true" href="#chatgpt">#</a></h4>
<ul>
<li>A version of GPT-3 that has been fine-tuned on a large dataset of conversational data</li>
<li>Designed to be used in chatbots or virtual assistants to provide more human-like interactions with users</li>
<li>Specifically trained to generate more natural and engaging conversations with users</li>
<li>Goal is to simulate human conversation as closely as possible</li>
<li>Can generate text in response to natural language inputs from users</li>
</ul>
<p>ChatGPT uses a technique called &ldquo;contextualization&rdquo; to incorporate the previous turns of the conversation into its responses.
When a user inputs a message, ChatGPT analyzes the message along with the previous messages in the conversation to
generate a response that is relevant to the ongoing discussion.</p>
<p>By using contextualization, ChatGPT is able to maintain coherence and relevancy throughout a conversation. But while
contextualization is an important technique that allows ChatGPT to incorporate previous turns in a conversation into its
responses, it can also potentially affect the correctness of its replies.</p>
<p>One potential issue with contextualization is that if the previous messages in the conversation are unclear, ambiguous,
or incorrect, ChatGPT may use this flawed context to generate its response, resulting in an incorrect or irrelevant
reply. Additionally, if a conversation takes unexpected turns or introduces new concepts or topics that are outside the
scope of the data that ChatGPT was trained on, it may generate less accurate or less relevant responses.</p>
<p>Access to full GPT3.5 model: <a href="https://platform.openai.com/playground/">https://platform.openai.com/playground/</a> (at the time of publishing)</p>
<p>Written with my co-writer, ChatGPT.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://alex-y-su.github.io/">Alex Su ⌗ personal</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
